{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install thop\n",
        "!pip install filesplit;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZJ_cCq_zwI5",
        "outputId": "86a91b83-bc0c-4e5d-b811-32148be7cf25"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "Collecting filesplit\n",
            "  Downloading filesplit-4.1.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading filesplit-4.1.0-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: filesplit\n",
            "Successfully installed filesplit-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from filesplit.merge import Merge\n",
        "\n",
        "merge = Merge('splitted_checkpoints', 'checkpoints', 'best_checkpoint.pth')\n",
        "merge.merge()"
      ],
      "metadata": {
        "id": "dfEI5urZ0zAs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7BaiY9Rvt7P",
        "outputId": "8cf2dc4b-b34f-4556-be82-0d3294fcc605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n",
            "Block Initial Type: W, drop_path_rate:0.000000\n",
            "Block Initial Type: SW, drop_path_rate:0.000000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "from matplotlib.dates import _epoch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import models\n",
        "from models.network_scunet import SCUNet\n",
        "\n",
        "# Initialize model\n",
        "#model = SCUNet(in_nc=1, config=[4, 4, 4, 4, 4, 4, 4], dim=64)\n",
        "# Now, we are using this config with extended dataset i.e., JNU, BUS and XPIE dataset.\n",
        "SCUNet()\n",
        "model = SCUNet(in_nc=1, config=[2,2,2,2,2,2,2], dim=64)\n",
        "\n",
        "# Initialize checkpoint epoch.\n",
        "# checkpoint_epoch = 2000\n",
        "# checkpoint = torch.load('checkpoints/epoch_' + str(checkpoint_epoch) + '_checkpoint.pth')\n",
        "# Load best model checkpoint\n",
        "checkpoint = torch.load('checkpoints/best_checkpoint.pth')\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Function to remove padding\n",
        "def remove_padding_val(img_tensor, pad_sizes):\n",
        "    pad_w_left, pad_w_right = pad_sizes[0], pad_sizes[1]  # padding widths\n",
        "    pad_h_top, pad_h_bottom = pad_sizes[2], pad_sizes[3]  # padding heights\n",
        "    h, w = img_tensor.shape[2], img_tensor.shape[3]\n",
        "    cropped_img = img_tensor[:, :, pad_h_top:h - pad_h_bottom, pad_w_left:w - pad_w_right]\n",
        "    return cropped_img\n",
        "\n",
        "# Initialize noise and blur levels.\n",
        "# gaussian_noise_level = [0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08,\n",
        "# 0.09, 0.10]\n",
        "# speckle_noise_level = [1, 3, 5, 7, 10, 13, 15, 17, 20, 23, 25]\n",
        "# blur_level = [0, 1, 3, 5, 7, 9, 11, 13, 15]\n",
        "test_noise_mode='speckle'\n",
        "test_noise_level=25\n",
        "test_blur_level=0\n",
        "\n",
        "# print(f'Noise level: {test_noise_level}')\n",
        "# Validation/Test dataloader\n",
        "original_dir = 'datasets/XPIE/object'\n",
        "filtered_dir = 'datasets/XPIE/object'\n",
        "dataset_name = \"XPIE_Object_test_dataset\"\n",
        "from DenoisingXPIETestDataset import *\n",
        "XPIE_test_dataset = DenoisingXPIETestDataset(original_dir, filtered_dir, \\\n",
        "                                            phase='test', target_filter='', \\\n",
        "                                            test_noise_level=test_noise_level, \\\n",
        "                                            test_blur_level=test_blur_level, \\\n",
        "                                            test_noise_mode=test_noise_mode)\n",
        "test_loader = DataLoader(XPIE_test_dataset, batch_size=1, shuffle=False, )\n",
        "\n",
        "results_dir = os.path.join('results', dataset_name, 'best_checkpoint_epoch', \\\n",
        "                            'test_noise_mode_' + test_noise_mode + '_test_noise_level_' + \\\n",
        "                            str(test_noise_level) + '_test_blur_level_' + str(test_blur_level))\n",
        "\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Loop through test dataset\n",
        "with torch.no_grad():\n",
        "    for idx, (original_images, degraded_images, filtered_images, pad_sizes) in enumerate(test_loader):\n",
        "        original_images = original_images.float().to(device)  # Convert to float\n",
        "        degraded_images = degraded_images.float().to(device)\n",
        "        filtered_images = filtered_images.float().to(device)\n",
        "\n",
        "        # Model inference\n",
        "        original_outputs = model(original_images)\n",
        "        outputs = model(degraded_images)\n",
        "        # print(original_images.shape, outputs.shape, pad_sizes)\n",
        "        outputs = remove_padding_val(outputs, torch.stack(pad_sizes))\n",
        "        # print(original_images.shape, outputs.shape)\n",
        "        degraded_images = remove_padding_val(degraded_images, pad_sizes)\n",
        "        original_images = remove_padding_val(original_images, pad_sizes)\n",
        "        # print(\"Images Shape: \", original_images.shape, outputs.shape, pad_sizes)\n",
        "\n",
        "\n",
        "        # Save images as PNG files\n",
        "        original_input_img_path = os.path.join(results_dir, f'original_input_{idx}.png')\n",
        "        degraded_input_img_path = os.path.join(results_dir, f'degraded_input_{idx}.png')\n",
        "        original_output_img_path = os.path.join(results_dir, f'original_output_{idx}.png')\n",
        "        denoised_output_img_path = os.path.join(results_dir, f'denoised_output_{idx}.png')\n",
        "        target_img_path = os.path.join(results_dir, f'target_{idx}.png')\n",
        "        # print(\"Squeezed Image\", original_images.squeeze(0).shape)\n",
        "        # print(original_images)\n",
        "        save_image(original_images.squeeze(0), original_input_img_path)  # Save original input image\n",
        "        save_image(degraded_images.squeeze(0), degraded_input_img_path)  # Save degraded input image\n",
        "        save_image(original_outputs.squeeze(0), original_output_img_path)         # Save original output image from non degraded input\n",
        "        save_image(outputs.squeeze(0), denoised_output_img_path)         # Save output (denoised) image\n",
        "        save_image(filtered_images.squeeze(0), target_img_path) # Save target image"
      ]
    }
  ]
}